{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7738259-790a-4702-b288-49a6250e5d4a",
   "metadata": {},
   "source": [
    "#### This custom kernel should have PyTorch and Huggingface already installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b342f7-cf90-43de-81fb-0c67e36f78ad",
   "metadata": {},
   "source": [
    "## ReviewSummarizer\n",
    "#### Goal:\r\n",
    "Build a dashboard using the BERT and Pegasus Transformer Encoder/Decoder models to provide digestable analytics on a restaurants performance.\r\n",
    "\r\n",
    "We scrap Yelp! reviews on an inputted restaurant name.\r\n",
    "We pass each review into BERT to produce an associated rating column\r\n",
    "We graph the distribution of high/low comments, giving the viewer an understanding of outlying observations and general trend regarding reviews\r\n",
    "We pass the first and last quartile of reviews into Pegasus to produce the summarized reason why the 1st quartile gave such low reviews, and why the last quartile gave such nice reviews.\r\n",
    "This tool is ment to help restaurants acquire a deep insight into the relationship with their audience, to understand the prevelance/extremity of certain complements and criticisms, along with quick pointers on how to fix the restaurant's most pressing issues/capture it's most successful\n",
    "\n",
    "#### Note:\n",
    "This will be written as an executable script with arguments for the input string representing the name and city of the restaurant on Yelp! trait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c944676b-0e17-4dbe-9b56-367dd27fdec6",
   "metadata": {},
   "source": [
    "### STEP 1: Scraping Pipeline with BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce922de3-1fc3-4bb9-9971-47b4288e2997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "print('HI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3987c5ad-35f3-4665-aa5a-86a5a72dc41b",
   "metadata": {},
   "source": [
    "### STEP 2: Scoring w/ BERT, HuggingFace Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82836e23-12c5-4ca0-8f70-569fcbe295a8",
   "metadata": {},
   "source": [
    "### STEP 3: Distribution Plot w/ Seaborn, EXPAND THIS FURTHER WITH MORE ANALYTICS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e4ec9-6f36-445e-9d61-2140c1395c24",
   "metadata": {},
   "source": [
    "### STEP 4: Summarization of first, last quantile using Pegasus, quantifying error in summarization \n",
    "(how representative is this summarization of all the comments in this quartile?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8edb0e2-b965-4ac8-84c7-59b493310964",
   "metadata": {},
   "source": [
    "##### 4.1 Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0df24-0bff-4648-a491-c790fdac2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install PyTorch, HuggingFace Transformers Library, SentencePiece\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "# !conda install -c huggingface transformers\n",
    "# !conda install -c conda-forge sentencepiece\n",
    "import sys\n",
    "#!{sys.executable} -m pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e494a75-df4d-4977-864b-f14f3a4eb17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbila\\anaconda3\\envs\\reviewHero\\python.exe: No module named conda\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e2fa97-949a-4b44-b2d9-7e66a4a55977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998656511306763}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable}  -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcb0c43-d624-4e76-aae3-167cd1de0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Dependencies from Transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af226a6-63af-462e-ba1a-6b4f7379ed7e",
   "metadata": {},
   "source": [
    "#### 4.2: Instantiate, Encode + Decode Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4da522-550a-4723-b18e-f9365e37e5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c68ec189fb4814b3820fbd4ef691ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbila\\anaconda3\\envs\\reviewHero\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mbila\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb78acca6404459b6409aff5da834d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4659c3a166e2418a92779c5c57df349a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724f3e82e9664922b59bda8742d6b711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Initialize Tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804957aa-500b-4268-a505-30da398e4948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74db62fd83343dc879f6c67c3547282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Initialize Model\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f0b15-9eb7-4b3f-bab2-7fd404e16cac",
   "metadata": {},
   "source": [
    "##### 4.2 Summarization of Example Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cea8da7c-986b-4d2b-b3c4-a1c297210efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "    Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.[31]\n",
    "\n",
    "Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.[32][33]\n",
    "\n",
    "Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0.[34] Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.[35]\n",
    "\n",
    "Python consistently ranks as one of the most popular programming languages.\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a89dfc0-e1e4-4f08-8b50-8403e12f8968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[11994,   117,   114,   281,   121,  3393,   108,   956,   121, 14621,\n",
       "          3661,  1261,   107,  3096,   354,  4679, 18390,   929, 39331,   122,\n",
       "           109,   207,   113,  1225, 58339,   107,  4101, 10822,  1100, 11994,\n",
       "           117, 22717, 23937,   111,  9041,   121, 83800,   107,   168,  3000,\n",
       "          1079,  3661, 50877,   108,   330,  7314,   143, 24899, 22000,   312,\n",
       "          2951,   121,  8321,   111,  3819,  3661,   107,   168,   117,   432,\n",
       "          2540,   130,   114,   198, 18077,   144, 32300,   953,   194,  1261,\n",
       "           640,   112,   203,  2250,   971,  2400,   107,  4101,  6695, 32887,\n",
       "          9773,  1100, 58937,  4406,  7366,  3707,  1219,   375,   124, 11994,\n",
       "           115,   109,  1095,  5940,   116,   130,   114, 15749,   112,   109,\n",
       "          8172,  3661,  1261,   111,   211,  1291,   126,   115, 12086,   130,\n",
       "         11994, 21544,   107, 24613,  4101, 12365,  1100, 11994,  4586,   140,\n",
       "          1291,   115, 13807, 11994,  9179,   108,  1291,   115,  7830,   140,\n",
       "           114,   698, 11827,   146,  1127, 17868,   121, 37804,   122,  1678,\n",
       "          3328,   107, 11994, 21672,   107,  4876,   108,  1291,   115, 21781,\n",
       "           140,   109,   289,  1131,   113, 11994,   280,   107,  4101,  7393,\n",
       "          1100, 11994,  4409,  7329,   130,   156,   113,   109,   205,   785,\n",
       "          3661,  4482,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokens of text from b4\n",
    "tokens = tokenizer(text, truncation=True, padding='longest', return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cafdf8d8-df54-405e-9482-2ffd86489371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 11994,   117,   114,  3661,  1261,  1184,   141, 58937,  4406,\n",
       "          7366,  3707,   107,     1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Output generation with Pegasus model\n",
    "summary = model.generate(**tokens)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8ce3edb-6c5a-46f4-af9f-389bc4817db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>Python is a programming language developed by Guido van Rossum.</s>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Decoding Summary\n",
    "tokenizer.decode(summary[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reviewHero3",
   "language": "python",
   "name": "reviewhero3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
